list(
red   = tidy(cor_red_alc_spearman),
white = tidy(cor_white_alc_spearman)
)
# Display Mann-Whitney U test results
mann_whitney_test <- wilcox.test(quality ~ type, data = data)
tidy(mann_whitney_test)
# Sample sizes
glue::glue("Red: {nrow(red)}, White: {nrow(white)}, Total: {nrow(data)}")
# Structure and summary
glimpse(data)
summary(data)
colSums(is.na(data))
ggplot(data, aes(x = factor(quality), fill = type)) +
geom_bar(position = "dodge") +
labs(title = "Quality Score Distribution",
x = "Quality Score", y = "Count") +
theme_minimal()
features <- c("alcohol", "pH", "residual.sugar", "volatile.acidity")
plot_list <- lapply(features, function(feat) {
ggplot(data, aes(x = type, y = .data[[feat]])) +
geom_boxplot() +
labs(title = feat, y = feat) +
theme_minimal()
})
# Print all plots
a <- plot_list[[1]]
for(p in plot_list) print(p)
cor_red   <- cor(filter(data, type == "red")   %>% select(-type))
cor_white <- cor(filter(data, type == "white") %>% select(-type))
par(mfrow = c(1,2))
corrplot(cor_red,   main = "Red Wine",   mar = c(0,0,1,0))
corrplot(cor_white, main = "White Wine", mar = c(0,0,1,0))
par(mfrow = c(1,1))
ttest <- t.test(quality ~ type, data = data)
tidy(ttest)
cor_red_alc   <- cor.test(filter(data, type == "red")$alcohol,
filter(data, type == "red")$quality)
cor_white_alc <- cor.test(filter(data, type == "white")$alcohol,
filter(data, type == "white")$quality)
list(
red   = tidy(cor_red_alc),
white = tidy(cor_white_alc)
)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 7,
fig.height = 5
)
required_packages <- c("tidyverse", "broom", "corrplot")
to_install <- setdiff(required_packages, installed.packages()[, "Package"])
if (length(to_install) > 0) install.packages(to_install)
# Core libraries for data wrangling, plotting, and correlation analysis
library(tidyverse)
library(dplyr)       # ensure dplyr functions like bind_rows are available
library(broom)
library(corrplot)
# URLs for the datasets and other sources
red_url   <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
white_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
volatile_acidity_url <- "https://www.awri.com.au/wp-content/uploads/2018/03/s1982.pdf"
# Read data
red   <- read.csv(red_url, sep = ";")
white <- read.csv(white_url, sep = ";")
# Add type column
red$type   <- "red"
white$type <- "white"
# Combine using dplyr::bind_rows to ensure the function is found
data <- dplyr::bind_rows(red, white)
# Normality Check using Shapiro-Wilk Test
shapiro_red <- shapiro.test(filter(data, type == "red")$quality)
shapiro_white <- shapiro.test(filter(data, type == "white")$quality)
cat("Shapiro-Wilk Test for Red Wine:\n")
print(shapiro_red)
cat("\nShapiro-Wilk Test for White Wine:\n")
print(shapiro_white)
# Q-Q Plots for Normality
par(mfrow = c(1, 2))  # Set up the plotting window to show two plots side by side
qqnorm(filter(data, type == "red")$quality, main = "Q-Q Plot for Red Wine Quality")
qqline(filter(data, type == "red")$quality)
qqnorm(filter(data, type == "white")$quality, main = "Q-Q Plot for White Wine Quality")
qqline(filter(data, type == "white")$quality)
par(mfrow = c(1, 1))  # Reset the plotting window to default
# Homogeneity of Variances using Levene’s Test
library(car) # For leveneTest
levene_test <- leveneTest(quality ~ type, data = data)
cat("\nLevene's Test for Equality of Variances:\n")
print(levene_test)
# Correlation Testing
cor_red_alc <- cor.test(filter(data, type == "red")$alcohol, filter(data, type == "red")$quality)
cor_white_alc <- cor.test(filter(data, type == "white")$alcohol, filter(data, type == "white")$quality)
cat("\nCorrelation Test Results for Alcohol vs Quality:\n")
list(
red = tidy(cor_red_alc),
white = tidy(cor_white_alc)
)
# Scatter Plots for Alcohol vs Quality
par(mfrow = c(1, 2))  # Set up the plotting window to show two plots side by side
plot(filter(data, type == "red")$alcohol, filter(data, type == "red")$quality,
main = "Red Wine: Alcohol vs Quality",
xlab = "Alcohol", ylab = "Quality", pch = 19, col = "red")
plot(filter(data, type == "white")$alcohol, filter(data, type == "white")$quality,
main = "White Wine: Alcohol vs Quality",
xlab = "Alcohol", ylab = "Quality", pch = 19, col = "red")
par(mfrow = c(1, 1))  # Reset the plotting window to default
# Non-parametric correlation using Spearman's rank correlation
cor_red_alc_spearman <- cor.test(filter(data, type == "red")$alcohol,
filter(data, type == "red")$quality,
method = "spearman")
cor_white_alc_spearman <- cor.test(filter(data, type == "white")$alcohol,
filter(data, type == "white")$quality,
method = "spearman")
# Spearman's Rank Correlation Scatter Plot with Line of Best Fit
library(ggplot2)
ggplot(filter(data, type == "red"), aes(x = alcohol, y = quality)) +
geom_point(color = "red") +
geom_smooth(method = "lm", color = "black", linetype = "dashed") +
labs(title = "Spearman's Rank Correlation for Red Wine: Alcohol vs Quality",
x = "Alcohol", y = "Quality") +
theme_minimal()
ggplot(filter(data, type == "white"), aes(x = alcohol, y = quality)) +
geom_point(color = "white") +
geom_smooth(method = "lm", color = "black", linetype = "dashed") +
labs(title = "Spearman's Rank Correlation for White Wine: Alcohol vs Quality",
x = "Alcohol", y = "Quality") +
theme_minimal()
# Mann-Whitney U Test Boxplot
ggplot(data, aes(x = type, y = quality, fill = type)) +
geom_boxplot() +
labs(title = "Boxplot of Wine Quality by Type (Mann-Whitney U Test)",
x = "Wine Type", y = "Quality") +
theme_minimal()
# Display correlation test results
list(
red   = tidy(cor_red_alc_spearman),
white = tidy(cor_white_alc_spearman)
)
# Display Mann-Whitney U test results
mann_whitney_test <- wilcox.test(quality ~ type, data = data)
tidy(mann_whitney_test)
# Sample sizes
glue::glue("Red: {nrow(red)}, White: {nrow(white)}, Total: {nrow(data)}")
# Structure and summary
glimpse(data)
summary(data)
colSums(is.na(data))
ggplot(data, aes(x = factor(quality), fill = type)) +
geom_bar(position = "dodge") +
labs(title = "Quality Score Distribution",
x = "Quality Score", y = "Count") +
theme_minimal()
features <- c("alcohol", "pH", "residual.sugar", "volatile.acidity")
plot_list <- lapply(features, function(feat) {
ggplot(data, aes(x = type, y = .data[[feat]])) +
geom_boxplot() +
labs(title = feat, y = feat) +
theme_minimal()
})
# Print all plots
a <- plot_list[[1]]
for(p in plot_list) print(p)
cor_red   <- cor(filter(data, type == "red")   %>% select(-type))
cor_white <- cor(filter(data, type == "white") %>% select(-type))
par(mfrow = c(1,2))
corrplot(cor_red,   main = "Red Wine",   mar = c(0,0,1,0))
corrplot(cor_white, main = "White Wine", mar = c(0,0,1,0))
par(mfrow = c(1,1))
ttest <- t.test(quality ~ type, data = data)
tidy(ttest)
cor_red_alc   <- cor.test(filter(data, type == "red")$alcohol,
filter(data, type == "red")$quality)
cor_white_alc <- cor.test(filter(data, type == "white")$alcohol,
filter(data, type == "white")$quality)
list(
red   = tidy(cor_red_alc),
white = tidy(cor_white_alc)
)
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE,
fig.width = 7,
fig.height = 5
)
required_packages <- c("tidyverse", "broom", "corrplot")
to_install <- setdiff(required_packages, installed.packages()[, "Package"])
if (length(to_install) > 0) install.packages(to_install)
# Core libraries for data wrangling, plotting, and correlation analysis
library(tidyverse)
library(dplyr)       # ensure dplyr functions like bind_rows are available
library(broom)
library(corrplot)
# URLs for the datasets and other sources
red_url   <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
white_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv"
volatile_acidity_url <- "https://www.awri.com.au/wp-content/uploads/2018/03/s1982.pdf"
# Read data
red   <- read.csv(red_url, sep = ";")
white <- read.csv(white_url, sep = ";")
# Add type column
red$type   <- "red"
white$type <- "white"
# Combine using dplyr::bind_rows to ensure the function is found
data <- dplyr::bind_rows(red, white)
# Normality Check using Shapiro-Wilk Test
shapiro_red <- shapiro.test(filter(data, type == "red")$quality)
shapiro_white <- shapiro.test(filter(data, type == "white")$quality)
cat("Shapiro-Wilk Test for Red Wine:\n")
print(shapiro_red)
cat("\nShapiro-Wilk Test for White Wine:\n")
print(shapiro_white)
# Q-Q Plots for Normality
par(mfrow = c(1, 2))  # Set up the plotting window to show two plots side by side
qqnorm(filter(data, type == "red")$quality, main = "Q-Q Plot for Red Wine Quality")
qqline(filter(data, type == "red")$quality)
qqnorm(filter(data, type == "white")$quality, main = "Q-Q Plot for White Wine Quality")
qqline(filter(data, type == "white")$quality)
par(mfrow = c(1, 1))  # Reset the plotting window to default
# Homogeneity of Variances using Levene’s Test
library(car) # For leveneTest
levene_test <- leveneTest(quality ~ type, data = data)
cat("\nLevene's Test for Equality of Variances:\n")
print(levene_test)
# Correlation Testing
cor_red_alc <- cor.test(filter(data, type == "red")$alcohol, filter(data, type == "red")$quality)
cor_white_alc <- cor.test(filter(data, type == "white")$alcohol, filter(data, type == "white")$quality)
cat("\nCorrelation Test Results for Alcohol vs Quality:\n")
list(
red = tidy(cor_red_alc),
white = tidy(cor_white_alc)
)
# Scatter Plots for Alcohol vs Quality
par(mfrow = c(1, 2))  # Set up the plotting window to show two plots side by side
plot(filter(data, type == "red")$alcohol, filter(data, type == "red")$quality,
main = "Red Wine: Alcohol vs Quality",
xlab = "Alcohol", ylab = "Quality", pch = 19, col = "red")
plot(filter(data, type == "white")$alcohol, filter(data, type == "white")$quality,
main = "White Wine: Alcohol vs Quality",
xlab = "Alcohol", ylab = "Quality", pch = 19, col = "red")
par(mfrow = c(1, 1))  # Reset the plotting window to default
# Non-parametric correlation using Spearman's rank correlation
cor_red_alc_spearman <- cor.test(filter(data, type == "red")$alcohol,
filter(data, type == "red")$quality,
method = "spearman")
cor_white_alc_spearman <- cor.test(filter(data, type == "white")$alcohol,
filter(data, type == "white")$quality,
method = "spearman")
# Spearman's Rank Correlation Scatter Plot with Line of Best Fit
library(ggplot2)
ggplot(filter(data, type == "red"), aes(x = alcohol, y = quality)) +
geom_point(color = "red") +
geom_smooth(method = "lm", color = "black", linetype = "dashed") +
labs(title = "Spearman's Rank Correlation for Red Wine: Alcohol vs Quality",
x = "Alcohol", y = "Quality") +
theme_minimal()
ggplot(filter(data, type == "white"), aes(x = alcohol, y = quality)) +
geom_point(color = "white") +
geom_smooth(method = "lm", color = "black", linetype = "dashed") +
labs(title = "Spearman's Rank Correlation for White Wine: Alcohol vs Quality",
x = "Alcohol", y = "Quality") +
theme_minimal()
# Mann-Whitney U Test Boxplot
ggplot(data, aes(x = type, y = quality, fill = type)) +
geom_boxplot() +
labs(title = "Boxplot of Wine Quality by Type (Mann-Whitney U Test)",
x = "Wine Type", y = "Quality") +
theme_minimal()
# Display correlation test results
list(
red   = tidy(cor_red_alc_spearman),
white = tidy(cor_white_alc_spearman)
)
# Display Mann-Whitney U test results
mann_whitney_test <- wilcox.test(quality ~ type, data = data)
tidy(mann_whitney_test)
# Sample sizes
glue::glue("Red: {nrow(red)}, White: {nrow(white)}, Total: {nrow(data)}")
# Structure and summary
glimpse(data)
summary(data)
colSums(is.na(data))
ggplot(data, aes(x = factor(quality), fill = type)) +
geom_bar(position = "dodge") +
labs(title = "Quality Score Distribution",
x = "Quality Score", y = "Count") +
theme_minimal()
features <- c("alcohol", "pH", "residual.sugar", "volatile.acidity")
plot_list <- lapply(features, function(feat) {
ggplot(data, aes(x = type, y = .data[[feat]])) +
geom_boxplot() +
labs(title = feat, y = feat) +
theme_minimal()
})
# Print all plots
a <- plot_list[[1]]
for(p in plot_list) print(p)
cor_red   <- cor(filter(data, type == "red")   %>% select(-type))
cor_white <- cor(filter(data, type == "white") %>% select(-type))
par(mfrow = c(1,2))
corrplot(cor_red,   main = "Red Wine",   mar = c(0,0,1,0))
corrplot(cor_white, main = "White Wine", mar = c(0,0,1,0))
par(mfrow = c(1,1))
ttest <- t.test(quality ~ type, data = data)
tidy(ttest)
cor_red_alc   <- cor.test(filter(data, type == "red")$alcohol,
filter(data, type == "red")$quality)
cor_white_alc <- cor.test(filter(data, type == "white")$alcohol,
filter(data, type == "white")$quality)
list(
red   = tidy(cor_red_alc),
white = tidy(cor_white_alc)
)
# 1. Load libraries
library(dplyr)
library(broom)
library(ggplot2)
library(conflicted)
# 2. Loading the data
data <- read.csv("C:/Users/Kasey Cohen/Downloads/3_28_sql_output (7).csv")
# 3. Quick look
sink("summary_statistics.txt")
glimpse(data)
summarize_data <- data %>%
summarise(
min_count = min(endangered_species_count, na.rm = TRUE),
max_count = max(endangered_species_count, na.rm = TRUE),
mean_count = mean(endangered_species_count, na.rm = TRUE)
)
print(summarize_data)
sink()
# 4. Pearson correlation tests
cor_lat <- cor.test(data$endangered_species_count, data$lat)
cor_lon <- cor.test(data$endangered_species_count, data$lon)
# 5. Tidy up results
results <- bind_rows(
tidy(cor_lat) %>% mutate(variable = "latitude"),
tidy(cor_lon) %>% mutate(variable = "longitude")
) %>%
select(variable, estimate, p.value, conf.low, conf.high)
sink("Pearson_correlation_tests.txt")
print(results)
sink()
# 6. Scatter + regression plots
p1 <- ggplot(data, aes(lat, endangered_species_count)) +
geom_jitter(width = 0.2, alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(x = "Latitude", y = "Endangered Species Count", title = "Species Count vs Latitude") +
theme(aspect.ratio = 0.6)
print(p1)
ggsave("scatter_latitude_jitter.png", p1, width = 12, height = 8)
p2 <- ggplot(data, aes(lon, endangered_species_count)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "darkblue") +
labs(x = "Longitude", y = "Endangered Species Count", title = "Species Count vs Longitude") +
theme(aspect.ratio = 0.6)
print(p2)
ggsave("scatter_longitude_point.png", p2, width = 12, height = 8)
# 7. Spearman correlations
spearman_lat <- cor.test(data$endangered_species_count, data$lat, method = "spearman")
spearman_lon <- cor.test(data$endangered_species_count, data$lon, method = "spearman")
spearman_results <- bind_rows(
tidy(spearman_lat) %>% mutate(variable = "latitude"),
tidy(spearman_lon) %>% mutate(variable = "longitude")
) %>%
select(variable, estimate, p.value)
sink("Non_parametric_Spearman_correlations.txt")
print(spearman_results)
sink()
# 8. Multiple linear regression
model <- lm(endangered_species_count ~ lat + lon, data = data)
# 9. Model summary
sink("model_summary.txt")
print(broom::tidy(model))
print(broom::glance(model))
sink()
# 10. Residual diagnostics
par(mfrow = c(2,2))
plot(model)
par(mfrow = c(1,1))
# 11. State-level summary
if ("state" %in% names(data)) {
state_summary <- data %>%
group_by(state) %>%
summarise(
total_endangered = sum(endangered_species_count, na.rm = TRUE),
avg_endangered = mean(endangered_species_count, na.rm = TRUE),
parks_count = n()
) %>%
arrange(desc(total_endangered))
sink("State_level_summary.txt")
print(state_summary)
sink()
}
# 12. Latitude quartile analysis
lat_quartile <- data %>%
mutate(lat_q = ntile(lat, 4)) %>%
group_by(lat_q) %>%
summarise(mean_endangered = mean(endangered_species_count, na.rm = TRUE))
p3 <- ggplot(lat_quartile, aes(factor(lat_q), mean_endangered, fill = factor(lat_q))) +
geom_bar(stat = "identity") +
labs(x = "Latitude Quartile", y = "Mean Endangered Count", title = "Species by Latitude Quartile") +
theme(aspect.ratio = 0.6)
print(p3)
ggsave("latitude_quartile_barchart.png", p3, width = 12, height = 8)
# Load libraries
library(dplyr)
library(broom)
library(ggplot2)
library(conflicted)
library(car) # For Breusch-Pagan test
# Load data
data <- read.csv("C:/Users/Kasey Cohen/Downloads/3_28_sql_output (7).csv")
# Summary statistics
sink("summary_statistics.txt")
glimpse(data)
summarize_data <- data %>%
summarise(
min_count = min(endangered_species_count, na.rm = TRUE),
max_count = max(endangered_species_count, na.rm = TRUE),
mean_count = mean(endangered_species_count, na.rm = TRUE)
)
print(summarize_data)
sink()
# Pearson correlation tests
cor_lat <- cor.test(data$endangered_species_count, data$lat)
cor_lon <- cor.test(data$endangered_species_count, data$lon)
# Tidy correlation results
results <- bind_rows(
tidy(cor_lat) %>% mutate(variable = "latitude"),
tidy(cor_lon) %>% mutate(variable = "longitude")
) %>%
select(variable, estimate, p.value, conf.low, conf.high)
sink("Pearson_correlation_tests.txt")
print(results)
sink()
# Scatter + regression plots
p1 <- ggplot(data, aes(lat, endangered_species_count)) +
geom_jitter(width = 0.2, alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(x = "Latitude", y = "Endangered Species Count", title = "Species Count vs Latitude") +
theme(aspect.ratio = 0.6)
ggsave("scatter_latitude_jitter.png", p1, width = 12, height = 8)
p2 <- ggplot(data, aes(lon, endangered_species_count)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "darkblue") +
labs(x = "Longitude", y = "Endangered Species Count", title = "Species Count vs Longitude") +
theme(aspect.ratio = 0.6)
ggsave("scatter_longitude_point.png", p2, width = 12, height = 8)
# Multiple linear regression
model <- lm(endangered_species_count ~ lat + lon, data = data)
# Assumption Checks
sink("Assumption_Checks.txt")
# Normality of residuals
shapiro_test <- shapiro.test(residuals(model))
print(shapiro_test)
# Homoscedasticity
bp_test <- bptest(model)
# Load libraries
library(dplyr)
library(broom)
library(ggplot2)
library(conflicted)
library(car) # For Breusch-Pagan test
# Load data
data <- read.csv("C:/Users/Kasey Cohen/Downloads/3_28_sql_output (7).csv")
# Summary statistics
sink("summary_statistics.txt")
glimpse(data)
summarize_data <- data %>%
summarise(
min_count = min(endangered_species_count, na.rm = TRUE),
max_count = max(endangered_species_count, na.rm = TRUE),
mean_count = mean(endangered_species_count, na.rm = TRUE)
)
print(summarize_data)
sink()
# Pearson correlation tests
cor_lat <- cor.test(data$endangered_species_count, data$lat)
cor_lon <- cor.test(data$endangered_species_count, data$lon)
# Tidy correlation results
results <- bind_rows(
tidy(cor_lat) %>% mutate(variable = "latitude"),
tidy(cor_lon) %>% mutate(variable = "longitude")
) %>%
select(variable, estimate, p.value, conf.low, conf.high)
sink("Pearson_correlation_tests.txt")
print(results)
sink()
# Scatter + regression plots
p1 <- ggplot(data, aes(lat, endangered_species_count)) +
geom_jitter(width = 0.2, alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "red") +
labs(x = "Latitude", y = "Endangered Species Count", title = "Species Count vs Latitude") +
theme(aspect.ratio = 0.6)
ggsave("scatter_latitude_jitter.png", p1, width = 12, height = 8)
p2 <- ggplot(data, aes(lon, endangered_species_count)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = TRUE, color = "darkblue") +
labs(x = "Longitude", y = "Endangered Species Count", title = "Species Count vs Longitude") +
theme(aspect.ratio = 0.6)
ggsave("scatter_longitude_point.png", p2, width = 12, height = 8)
# Multiple linear regression
model <- lm(endangered_species_count ~ lat + lon, data = data)
# Assumption Checks
sink("Assumption_Checks.txt")
# Normality of residuals
shapiro_test <- shapiro.test(residuals(model))
print(shapiro_test)
# Homoscedasticity
bp_test <- bptest(model)
